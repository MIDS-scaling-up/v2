{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will continue on the [Conversation AI](https://conversationai.github.io/) dataset seen in [week 4 homework and lab](https://github.com/MIDS-scaling-up/v2/tree/master/week04). \n",
    "We shall use a version of pytorch BERT for classifying comments found at [https://github.com/huggingface/pytorch-pretrained-BERT](https://github.com/huggingface/pytorch-pretrained-BERT).  \n",
    "\n",
    "The original implementation of BERT is optimised for TPU. Google released some amazing performance improvements on TPU over GPU, for example, see [here](https://medium.com/@ranko.mosic/googles-bert-nlp-5b2bb1236d78) - *BERT relies on massive compute for pre-training ( 4 days on 4 to 16 Cloud TPUs; pre-training on 8 GPUs would take 40â€“70 days).*. In response, Nvidia released [apex](https://devblogs.nvidia.com/apex-pytorch-easy-mixed-precision-training/), which gave mixed precision training. Weights are stored in float32 format, but calculations, like forward and backward propagation happen in float16 - this allows these calculations to be made with a [4X speed up](https://github.com/huggingface/pytorch-pretrained-BERT/issues/149).  \n",
    "\n",
    "We shall apply BERT to the problem for classifiying toxicity, using apex from Nvidia. We shall compare the impact of hardware by running the model on a V100 and P100 and comparing the speed and accuracy in both cases.   \n",
    "\n",
    "This script relies heavily on an existing [Kaggle kernel](https://www.kaggle.com/yuval6967/toxic-bert-plain-vanila) from [yuval r](https://www.kaggle.com/yuval6967). \n",
    "  \n",
    "*Disclaimer: the dataset used contains text that may be considered profane, vulgar, or offensive.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test.csv.zip   100%[===================>]  12.09M  16.5MB/s    in 0.7s    \n",
      "2020-09-05 14:45:32 URL:https://ucbd522aa2f35fe4e5d53ca9fe52.dl.dropboxusercontent.com/cd/0/get/A-1gs2qoU7mKm0zSkW1frldEMMRfWNOE5rF8L51_DSnRabc33QM0QML3jUS1-hDNFcGFEYEjCPkfYlaDbj2jlRHpW4_gy2vo4a4aKuyO1p06Yl6gPw9oAJgdGkSX3g7P2x8/file?dl=1 [12673607/12673607] -> \"data/test.csv.zip\" [1]\n",
      "data/train.csv.zip  100%[===================>] 272.99M  17.5MB/s    in 16s     \n",
      "2020-09-05 14:45:49 URL:https://uc6e634ceae026916b5fc72e8b99.dl.dropboxusercontent.com/cd/0/get/A-3qDsywQu4wEa_crEhoOsOW1Nj_Gsk0Qa9UJop6wIt_Ao-FfZnjPpjOCMDR39P7fjipP5DRgkMjFhd4VrHFc62vJQ7FS6kJpYzHuTDm3zOtvK_B1LqEbsfqNFo4_5RJzO4/file?dl=1 [286248352/286248352] -> \"data/train.csv.zip\" [1]\n",
      "data/uncased_L-12_H 100%[===================>] 388.84M  24.1MB/s    in 13s     \n",
      "2020-09-05 14:46:02 URL:https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip [407727028/407727028] -> \"data/uncased_L-12_H-768_A-12.zip\" [1]\n",
      "data/cased_L-12_H-7 100%[===================>] 385.53M  24.8MB/s    in 12s     \n",
      "2020-09-05 14:46:15 URL:https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip [404261442/404261442] -> \"data/cased_L-12_H-768_A-12.zip\" [1]\n",
      "Archive:  data/cased_L-12_H-768_A-12.zip\n",
      "   creating: data/cased_L-12_H-768_A-12/\n",
      "  inflating: data/cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
      "  inflating: data/cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: data/cased_L-12_H-768_A-12/vocab.txt  \n",
      "  inflating: data/cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
      "  inflating: data/cased_L-12_H-768_A-12/bert_config.json  \n",
      "Archive:  data/uncased_L-12_H-768_A-12.zip\n",
      "   creating: data/uncased_L-12_H-768_A-12/\n",
      "  inflating: data/uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
      "  inflating: data/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: data/uncased_L-12_H-768_A-12/vocab.txt  \n",
      "  inflating: data/uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
      "  inflating: data/uncased_L-12_H-768_A-12/bert_config.json  \n"
     ]
    }
   ],
   "source": [
    "# Download the training and the test corpus\n",
    "!wget -nv --show-progress -O data/test.csv.zip https://www.dropbox.com/s/xp6bo8yo1vbv5yg/test.csv.zip?dl=1\n",
    "!wget -nv --show-progress -O data/train.csv.zip https://www.dropbox.com/s/xei6z41mfrcnxcd/train.csv.zip?dl=1\n",
    "# Download the pretrained weights for bert base. \n",
    "!wget -nv --show-progress -O data/uncased_L-12_H-768_A-12.zip \\\n",
    "        https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!wget -nv --show-progress  -O data/cased_L-12_H-768_A-12.zip \\\n",
    "        https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
    "# unzip weights & conifg and remove the original zip\n",
    "!unzip -d data/ data/cased_L-12_H-768_A-12.zip && rm data/cased_L-12_H-768_A-12.zip\n",
    "!unzip -d data/ data/uncased_L-12_H-768_A-12.zip && rm data/uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pickle\n",
    "from apex import amp\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's activate CUDA for GPU based operations\n",
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the PATH variable to whereever your `week06/hw` directory is located.  \n",
    "**For the final run we would like you to have a train_size of at least 1 Million rows, and a valid size of at least 500K rows. When you first run the script, feel free to work with a reduced train and valid size for speed.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In bert we need all inputs to have the same length, we will use the first 220 characters. \n",
    "MAX_SEQUENCE_LENGTH = 220\n",
    "SEED = 1234\n",
    "# We shall run a single epoch (ie. one pass over the data)\n",
    "EPOCHS = 1\n",
    "PATH = '/root/v2/week06/hw' # /root/v2/week06/hw\"\n",
    "DATA_DIR = os.path.join(PATH, \"data\")\n",
    "WORK_DIR = os.path.join(PATH, \"workingdir\")\n",
    "\n",
    "# Validation and training sizes are here. \n",
    "train_size= 10000 # 1000000 \n",
    "valid_size= 5000  # 500000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be the files you downloaded earlier when you ran `download.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv', 'download.sh']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall install pytorch BERT implementation.   \n",
    "If you would like to experiment with or view any code (purely optional, and not graded :) ), you can copy the files from the repo https://github.com/huggingface/pytorch-pretrained-BERT  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "# from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification,BertAdam\n",
    "# from pytorch_pretrained_bert.modeling import BertModel\n",
    "# from pytorch_pretrained_bert import BertConfig\n",
    "from transformers import BertModel, BertConfig, BertTokenizer, BertForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now load the model. When you run this, comment out the `capture` command to understand the archecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Translate model from tensorflow to pytorch\n",
    "# BERT_MODEL_PATH = os.path.join(DATA_DIR, 'uncased_L-12_H-768_A-12')\n",
    "# convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n",
    "#                             os.path.join(BERT_MODEL_PATH, 'bert_model.ckpt'),\n",
    "#                             os.path.join(BERT_MODEL_PATH, 'bert_config.json'), \n",
    "#                             os.path.join(WORK_DIR, 'pytorch_model.bin'))\n",
    "\n",
    "# shutil.copyfile(os.path.join(BERT_MODEL_PATH, 'bert_config.json'), \\\n",
    "#                 os.path.join(WORK_DIR, 'bert_config.json'))\n",
    "# This is the Bert configuration file\n",
    "# bert_config = BertConfig(os.path.join(WORK_DIR, 'bert_config.json'))\n",
    "\n",
    "bert_config = BertConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert needs a special formatting of sentences, so we have a sentence start and end token, as well as separators.   \n",
    "Thanks to this [script](https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming) for a fast convertor of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lines(example, max_seq_length,tokenizer):\n",
    "    max_seq_length -=2\n",
    "    all_tokens = []\n",
    "    longer = 0\n",
    "    for text in tqdm_notebook(example):\n",
    "        tokens_a = tokenizer.tokenize(text)\n",
    "        if len(tokens_a)>max_seq_length:\n",
    "            tokens_a = tokens_a[:max_seq_length]\n",
    "            longer += 1\n",
    "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n",
    "        all_tokens.append(one_token)\n",
    "    print(longer)\n",
    "    return np.array(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the BERT tokenizer and convert the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 15000 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606a3f04fdfa4b67b631f5f420e8e2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "358\n",
      "CPU times: user 51.4 s, sys: 4.07 s, total: 55.4 s\n",
      "Wall time: 55.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_all = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\")).sample(train_size+valid_size,random_state=SEED)\n",
    "print('loaded %d records' % len(train_all))\n",
    "\n",
    "# Make sure all comment_text values are strings\n",
    "train_all['comment_text'] = train_all['comment_text'].astype(str) \n",
    "\n",
    "sequences = convert_lines(train_all[\"comment_text\"].fillna(\"DUMMY_VALUE\"),MAX_SEQUENCE_LENGTH,tokenizer)\n",
    "train_all=train_all.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at how the tokenising works in BERT, see below how it recongizes misspellings - words the model never saw. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458232</th>\n",
       "      <td>It's difficult for many old people to keep up ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272766</th>\n",
       "      <td>She recognized that her tiny-handed husband is...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339129</th>\n",
       "      <td>HPHY76,\\nGood for you for thinking out loud, w...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773565</th>\n",
       "      <td>And I bet that in the day you expected your Je...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476233</th>\n",
       "      <td>Kennedy will add a much needed and scientifica...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text    target\n",
       "458232  It's difficult for many old people to keep up ...  0.000000\n",
       "272766  She recognized that her tiny-handed husband is...  0.166667\n",
       "339129  HPHY76,\\nGood for you for thinking out loud, w...  0.000000\n",
       "773565  And I bet that in the day you expected your Je...  0.500000\n",
       "476233  Kennedy will add a much needed and scientifica...  0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all[[\"comment_text\", 'target']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets tokenize some text (I intentionally mispelled some words to check berts subword information handling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi , i am learning new things in w ##25 ##1 about deep learning the cloud and te ##h edge .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hi, I am learning new things in w251 about deep learning the cloud and teh edge.'\n",
    "tokens = tokenizer.tokenize(text)\n",
    "' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added start and end token and convert to ids. This is how it is fed into BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'101 7632 1010 1045 2572 4083 2047 2477 1999 1059 17788 2487 2055 2784 4083 1996 6112 1998 8915 2232 3341 1012 102'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "' '.join(map(str, input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When BERT converts this sentence to a torch tensor below is shape of the stored tensors.  \n",
    "We have 12 input tensors, while the sentence tokens has length 23; where are can you see the 23 tokens in the tensors ?... **Feel free to post in slack or discuss in class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence tokens ['[CLS]', 'hi', ',', 'i', 'am', 'learning', 'new', 'things', 'in', 'w', '##25', '##1', 'about', 'deep', 'learning', 'the', 'cloud', 'and', 'te', '##h', 'edge', '.', '[SEP]']\n",
      "Number of tokens 23\n",
      "Tensor shapes : [(2,)]\n",
      "Number of torch tensors : 1\n"
     ]
    }
   ],
   "source": [
    "# put input on gpu and make prediction\n",
    "bert = BertForSequenceClassification.from_pretrained('bert-base-uncased').cuda()\n",
    "# bert = BertModel.from_pretrained(WORK_DIR).cuda()\n",
    "bert_output = bert(torch.tensor([input_ids]).cuda())\n",
    "\n",
    "print('Sentence tokens {}'.format(tokens))\n",
    "print('Number of tokens {}'.format(len(tokens)))\n",
    "print('Tensor shapes : {}'.format([b.cpu().detach().numpy().shape for b in bert_output[0]]))\n",
    "print('Number of torch tensors : {}'.format(len(bert_output[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is a binary problem, we change our target to [0,1], instead of float.   \n",
    "We also split the dataset into a training and validation set, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['target']=(train_all['target']>=0.5).astype(float)\n",
    "# Training data - sentences\n",
    "X = sequences[:train_size] \n",
    "# Target - the toxicity. \n",
    "y = train_all[['target']].values[:train_size]\n",
    "X_val = sequences[train_size:]                \n",
    "y_val = train_all[['target']].values[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=train_all.tail(valid_size).copy()\n",
    "train_df=train_all.head(train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From here on in we would like you to run BERT.**   \n",
    "**Please do rely on the script available -  [Kaggle kernel](https://www.kaggle.com/yuval6967/toxic-bert-plain-vanila) from [yuval r](https://www.kaggle.com/yuval6967) - for at least the first few steps up to training and prediction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1)**   \n",
    "**Load the training set to a training dataset. For this you need to load the X sequences and y objects to torch tensors**   \n",
    "**You can use `torch.utils.data.TensorDataset` to input these into a train_dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data creations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)**  \n",
    "**Set your learning rate and batch size; and optionally random seeds if you want reproducable results**   \n",
    "**Load your pretrained BERT using `BertForSequenceClassification`**   \n",
    "**Initialise the gradients and place the model on cuda, set up your optimiser and decay parameters**\n",
    "**Initialise the model with `apex` (we imprted this as `amp`) for mixed precision training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)**  \n",
    "**Start training your model by iterating through batches in a single epoch of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)**  \n",
    "**Store your trained model to disk, you will need it if you choose section 8C.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)**   \n",
    "**Now make a prediction for your validation set.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)**  \n",
    "**In the yuval's kernel he get a metric based on the metric for the jigsaw competition - it is quite complicated. Instead, we would like you to measure the `AUC`, similar to how you did in homework 04. You can compare the results to HW04**  \n",
    "*A tip, if your score is lower than homework 04 something is wrong....*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)**  \n",
    "**Can you show/print the validation sentences predicted with the highest and lowest toxicity ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8)**  \n",
    "**Pick only one of the below items and complete it. The last two will take a good amount of time (and partial success on them is fine), so proceed with caution on your choice of items :)** \n",
    "  \n",
    "  \n",
    "**A. Can you train on two epochs ?**\n",
    "\n",
    "**B. Can you change the learning rate and improve validation score ?**\n",
    "   \n",
    "**C. Make a prediction on the test data set with your downloaded model and submit to Kaggle to see where you score on public LB - check out [Abhishek's](https://www.kaggle.com/abhishek) script - https://www.kaggle.com/abhishek/pytorch-bert-inference . Note, you will need to fork Abhisheks kernel, swap out the weights to your downloaded weights and commit the kernel. When finalised and you get the output, there is a button to submit to the competition**  \n",
    "  \n",
    "**D. Get BERT running on the tx2 for a sample of the data.** \n",
    "  \n",
    "**E. Finally, and very challenging -- the `BertAdam` optimiser proved to be suboptimal for this task. There is a better optimiser for this dataset in this script [here](https://www.kaggle.com/cristinasierra/pretext-lstm-tuning-v3). Check out the `custom_loss` function. Can you implement it ? It means getting under the hood of the `BertForSequenceClassification` at the source repo and implementing a modified version locally .  `https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
